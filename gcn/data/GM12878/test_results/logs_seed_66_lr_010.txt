Epoch: 0001 train_loss= 0.70148 train_acc= 0.34211 val_loss= 0.69860 val_acc= 0.67790 time= 0.23733
Epoch: 0002 train_loss= 0.69806 train_acc= 0.75940 val_loss= 0.69597 val_acc= 0.67790 time= 0.12588
Epoch: 0003 train_loss= 0.69502 train_acc= 0.77820 val_loss= 0.69361 val_acc= 0.67790 time= 0.13643
Epoch: 0004 train_loss= 0.69070 train_acc= 0.77820 val_loss= 0.69154 val_acc= 0.67790 time= 0.13139
Epoch: 0005 train_loss= 0.68739 train_acc= 0.77820 val_loss= 0.68975 val_acc= 0.67790 time= 0.12795
Epoch: 0006 train_loss= 0.68464 train_acc= 0.77444 val_loss= 0.68823 val_acc= 0.67790 time= 0.12942
Epoch: 0007 train_loss= 0.68134 train_acc= 0.77820 val_loss= 0.68694 val_acc= 0.67790 time= 0.13028
Epoch: 0008 train_loss= 0.67808 train_acc= 0.77820 val_loss= 0.68585 val_acc= 0.67790 time= 0.13160
Epoch: 0009 train_loss= 0.67446 train_acc= 0.77820 val_loss= 0.68496 val_acc= 0.67790 time= 0.13336
Epoch: 0010 train_loss= 0.67059 train_acc= 0.77820 val_loss= 0.68425 val_acc= 0.67790 time= 0.12763
Epoch: 0011 train_loss= 0.67295 train_acc= 0.77820 val_loss= 0.68370 val_acc= 0.67790 time= 0.13085
Epoch: 0012 train_loss= 0.66250 train_acc= 0.77820 val_loss= 0.68331 val_acc= 0.67790 time= 0.13418
Epoch: 0013 train_loss= 0.66446 train_acc= 0.77820 val_loss= 0.68308 val_acc= 0.67790 time= 0.13656
Epoch: 0014 train_loss= 0.65641 train_acc= 0.77820 val_loss= 0.68304 val_acc= 0.67790 time= 0.13550
Epoch: 0015 train_loss= 0.65560 train_acc= 0.77820 val_loss= 0.68322 val_acc= 0.67790 time= 0.13426
Epoch: 0016 train_loss= 0.65297 train_acc= 0.77820 val_loss= 0.68356 val_acc= 0.67790 time= 0.12756
Epoch: 0017 train_loss= 0.64832 train_acc= 0.77820 val_loss= 0.68409 val_acc= 0.67790 time= 0.12624
Epoch: 0018 train_loss= 0.65052 train_acc= 0.77820 val_loss= 0.68473 val_acc= 0.67790 time= 0.12400
Early stopping...
Optimization Finished!
Test set results: cost= 0.65875 accuracy= 0.74345 time= 0.07254