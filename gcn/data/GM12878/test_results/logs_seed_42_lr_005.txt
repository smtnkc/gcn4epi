Epoch: 0001 train_loss= 0.70110 train_acc= 0.42105 val_loss= 0.69833 val_acc= 0.71429 time= 0.23645
Epoch: 0002 train_loss= 0.69847 train_acc= 0.69173 val_loss= 0.69551 val_acc= 0.71429 time= 0.12381
Epoch: 0003 train_loss= 0.69528 train_acc= 0.69925 val_loss= 0.69294 val_acc= 0.71429 time= 0.13354
Epoch: 0004 train_loss= 0.69320 train_acc= 0.69925 val_loss= 0.69066 val_acc= 0.71429 time= 0.13009
Epoch: 0005 train_loss= 0.69053 train_acc= 0.69925 val_loss= 0.68858 val_acc= 0.71429 time= 0.12473
Epoch: 0006 train_loss= 0.68855 train_acc= 0.69173 val_loss= 0.68669 val_acc= 0.71429 time= 0.13183
Epoch: 0007 train_loss= 0.68705 train_acc= 0.69925 val_loss= 0.68495 val_acc= 0.71429 time= 0.13099
Epoch: 0008 train_loss= 0.68412 train_acc= 0.69173 val_loss= 0.68332 val_acc= 0.71429 time= 0.13051
Epoch: 0009 train_loss= 0.68470 train_acc= 0.69173 val_loss= 0.68181 val_acc= 0.71429 time= 0.13487
Epoch: 0010 train_loss= 0.68212 train_acc= 0.69925 val_loss= 0.68042 val_acc= 0.71429 time= 0.12783
Epoch: 0011 train_loss= 0.68020 train_acc= 0.69173 val_loss= 0.67904 val_acc= 0.71429 time= 0.12595
Epoch: 0012 train_loss= 0.68279 train_acc= 0.69925 val_loss= 0.67764 val_acc= 0.71429 time= 0.13395
Epoch: 0013 train_loss= 0.67528 train_acc= 0.69925 val_loss= 0.67629 val_acc= 0.71429 time= 0.13292
Epoch: 0014 train_loss= 0.67702 train_acc= 0.69925 val_loss= 0.67505 val_acc= 0.71429 time= 0.13368
Epoch: 0015 train_loss= 0.67483 train_acc= 0.69925 val_loss= 0.67396 val_acc= 0.71429 time= 0.13263
Epoch: 0016 train_loss= 0.67052 train_acc= 0.69925 val_loss= 0.67278 val_acc= 0.71429 time= 0.13085
Epoch: 0017 train_loss= 0.67008 train_acc= 0.69925 val_loss= 0.67164 val_acc= 0.71429 time= 0.12656
Epoch: 0018 train_loss= 0.67187 train_acc= 0.69925 val_loss= 0.67076 val_acc= 0.71429 time= 0.12705
Epoch: 0019 train_loss= 0.66961 train_acc= 0.69925 val_loss= 0.67008 val_acc= 0.71429 time= 0.12972
Epoch: 0020 train_loss= 0.66689 train_acc= 0.69925 val_loss= 0.66951 val_acc= 0.71429 time= 0.13249
Epoch: 0021 train_loss= 0.67046 train_acc= 0.69925 val_loss= 0.66905 val_acc= 0.71429 time= 0.13032
Epoch: 0022 train_loss= 0.65966 train_acc= 0.69925 val_loss= 0.66856 val_acc= 0.71429 time= 0.13316
Epoch: 0023 train_loss= 0.67051 train_acc= 0.69925 val_loss= 0.66810 val_acc= 0.71429 time= 0.13153
Epoch: 0024 train_loss= 0.66531 train_acc= 0.69925 val_loss= 0.66794 val_acc= 0.71429 time= 0.13213
Epoch: 0025 train_loss= 0.65753 train_acc= 0.69925 val_loss= 0.66786 val_acc= 0.71429 time= 0.13429
Epoch: 0026 train_loss= 0.65056 train_acc= 0.69925 val_loss= 0.66771 val_acc= 0.71429 time= 0.13243
Epoch: 0027 train_loss= 0.65377 train_acc= 0.69925 val_loss= 0.66758 val_acc= 0.71429 time= 0.12798
Epoch: 0028 train_loss= 0.65473 train_acc= 0.69925 val_loss= 0.66763 val_acc= 0.71429 time= 0.12795
Epoch: 0029 train_loss= 0.64670 train_acc= 0.69925 val_loss= 0.66768 val_acc= 0.71429 time= 0.13193
Epoch: 0030 train_loss= 0.63969 train_acc= 0.69925 val_loss= 0.66779 val_acc= 0.71429 time= 0.12985
Epoch: 0031 train_loss= 0.66754 train_acc= 0.69925 val_loss= 0.66805 val_acc= 0.71429 time= 0.13297
Early stopping...
Optimization Finished!
Test set results: cost= 0.64727 accuracy= 0.75281 time= 0.06435