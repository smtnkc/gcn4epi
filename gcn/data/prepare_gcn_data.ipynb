{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN data requirements:\n",
    "\n",
    "https://github.com/kimiyoung/planetoid#prepare-the-data\n",
    "\n",
    "https://github.com/tkipf/gcn#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "SEED = 42\n",
    "LABEL_RATE = 0.2 # [0.2, 0.1, 0.05]\n",
    "random.seed(SEED)\n",
    "CELL_LINE = 'GM12878'\n",
    "K_MER = 5\n",
    "TEST_EID = 981 # arbitrary enhancer id to be used tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new DF where each element is a tuple of 3 elements: (id, name, sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeById(df_ep, node_id):\n",
    "    for row in range(len(df_ep)):\n",
    "        enh = df_ep['enhancer'][row]\n",
    "        pro = df_ep['promoter'][row]\n",
    "        if enh[0] == node_id:\n",
    "            return enh\n",
    "        elif pro[0] == node_id:\n",
    "            return pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enhancer</th>\n",
       "      <th>promoter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1265, GM12878|chr1:9685722-9686400, TGACA GAC...</td>\n",
       "      <td>(1266, GM12878|chr1:9747084-9749721, TTTTG TTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1199, GM12878|chr1:24136556-24136600, GTGGC T...</td>\n",
       "      <td>(1205, GM12878|chr1:24193468-24194871, TGAAT G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1200, GM12878|chr1:24136600-24136932, GAAAC A...</td>\n",
       "      <td>(1205, GM12878|chr1:24193468-24194871, TGAAT G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1201, GM12878|chr1:24137625-24137875, GTGCC T...</td>\n",
       "      <td>(1205, GM12878|chr1:24193468-24194871, TGAAT G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1202, GM12878|chr1:24139145-24139414, GCCCA C...</td>\n",
       "      <td>(1205, GM12878|chr1:24193468-24194871, TGAAT G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            enhancer  \\\n",
       "0  (1265, GM12878|chr1:9685722-9686400, TGACA GAC...   \n",
       "1  (1199, GM12878|chr1:24136556-24136600, GTGGC T...   \n",
       "2  (1200, GM12878|chr1:24136600-24136932, GAAAC A...   \n",
       "3  (1201, GM12878|chr1:24137625-24137875, GTGCC T...   \n",
       "4  (1202, GM12878|chr1:24139145-24139414, GCCCA C...   \n",
       "\n",
       "                                            promoter  \n",
       "0  (1266, GM12878|chr1:9747084-9749721, TTTTG TTT...  \n",
       "1  (1205, GM12878|chr1:24193468-24194871, TGAAT G...  \n",
       "2  (1205, GM12878|chr1:24193468-24194871, TGAAT G...  \n",
       "3  (1205, GM12878|chr1:24193468-24194871, TGAAT G...  \n",
       "4  (1205, GM12878|chr1:24193468-24194871, TGAAT G...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ep_sentences = pd.read_csv('{}/ep_sentences_{}mer.csv'.format(CELL_LINE, K_MER))\n",
    "\n",
    "e_list = []\n",
    "p_list = []\n",
    "\n",
    "for i in range(len(df_ep_sentences)):\n",
    "    e_list.append( (df_ep_sentences['enhancer_name'][i], df_ep_sentences['enhancer_sentence'][i]) )\n",
    "    p_list.append( (df_ep_sentences['promoter_name'][i], df_ep_sentences['promoter_sentence'][i]) )\n",
    "\n",
    "x_list = sorted(list(set(list(df_ep_sentences['enhancer_name']) + list(df_ep_sentences['promoter_name']))))\n",
    "\n",
    "id_dict = {}\n",
    "chr_id = 0\n",
    "for x in x_list:\n",
    "    id_dict[x] = chr_id\n",
    "    chr_id += 1\n",
    "    \n",
    "# DUMP ID_DICT\n",
    "nodes_file = open('{}/nodes'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(id_dict, nodes_file)\n",
    "nodes_file.close()\n",
    "\n",
    "for i in range(len(e_list)):\n",
    "    e_list[i] = (id_dict[e_list[i][0]], ) + e_list[i]\n",
    "    \n",
    "for i in range(len(p_list)):\n",
    "    p_list[i] = (id_dict[p_list[i][0]], ) + p_list[i]\n",
    "\n",
    "df_ep = pd.DataFrame({'enhancer': e_list, 'promoter': p_list})\n",
    "display(df_ep.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981, 'GM12878|chr19:39930827-39930919', 'ACAAA CAAAT AAATG AATGA ATGAT TGATG GATGA ATGAT TGATG GATGA ATGAT TGATG GATGA ATGAC TGACT GACTA ACTAC CTACA TACAG ACAGC CAGCT AGCTG GCTGC CTGCA TGCAT GCATG CATGT ATGTA TGTAA GTAAA TAAAT AAATA AATAG ATAGT TAGTG AGTGT GTGTT TGTTT GTTTA TTTAC TTACT TACTC ACTCT CTCTG TCTGT CTGTG TGTGC GTGCC TGCCA GCCAG CCAGG CAGGT AGGTA GGTAT GTATT TATTG ATTGG TTGGT TGGTT GGTTT GTTTA TTTAA TTAAA TAAAT AAATG AATGC ATGCT TGCTT GCTTT CTTTA TTTAA TTAAG TAAGT AAGTA AGTAT GTATG TATGT ATGTT TGTTA GTTAG TTAGC TAGCT AGCTT GCTTA CTTAT TTATT TATTT ATTTA TTTAC') \n",
      "\n",
      "Test sentence length = 89\n"
     ]
    }
   ],
   "source": [
    "test_enh = getNodeById(df_ep, TEST_EID)\n",
    "print('{} \\n'.format(test_enh))\n",
    "print('Test sentence length = {}'.format(len(test_enh[2].split(' '))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE ADJACENCY MATRIX (NxN)\n",
    "\n",
    "N = Number of nodes (enhancers + promoters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samet/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2668x2668 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 4226 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adj = sp.csr_matrix((len(id_dict), len(id_dict)), dtype=np.int32)\n",
    "\n",
    "for i in range(len(df_ep)):\n",
    "    x = df_ep['enhancer'][i][0]\n",
    "    y = df_ep['promoter'][i][0]\n",
    "    adj[x,y] = 1\n",
    "    adj[y,x] = 1\n",
    "\n",
    "display(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancer 981 -> Promoter [983]\n"
     ]
    }
   ],
   "source": [
    "print('Enhancer {} -> Promoter {}'.format(TEST_EID, adj[TEST_EID].indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE FEATURE VECTORS (NxD)\n",
    "\n",
    "N = Number of nodes (enhancers + promoters)\n",
    "\n",
    "D = Number of words in vocabulary (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FOR ENHANCER 981 \n",
      "\n",
      "Length = 89 \n",
      "\n",
      "ACAAA CAAAT AAATG AATGA ATGAT TGATG GATGA ATGAT TGATG GATGA ATGAT TGATG GATGA ATGAC TGACT GACTA ACTAC CTACA TACAG ACAGC CAGCT AGCTG GCTGC CTGCA TGCAT GCATG CATGT ATGTA TGTAA GTAAA TAAAT AAATA AATAG ATAGT TAGTG AGTGT GTGTT TGTTT GTTTA TTTAC TTACT TACTC ACTCT CTCTG TCTGT CTGTG TGTGC GTGCC TGCCA GCCAG CCAGG CAGGT AGGTA GGTAT GTATT TATTG ATTGG TTGGT TGGTT GGTTT GTTTA TTTAA TTAAA TAAAT AAATG AATGC ATGCT TGCTT GCTTT CTTTA TTTAA TTAAG TAAGT AAGTA AGTAT GTATG TATGT ATGTT TGTTA GTTAG TTAGC TAGCT AGCTT GCTTA CTTAT TTATT TATTT ATTTA TTTAC\n"
     ]
    }
   ],
   "source": [
    "merged_list = list(set(list(df_ep['enhancer']) + list(df_ep['promoter'])))\n",
    "merged_list = sorted(merged_list) # sort by first element (id)\n",
    "\n",
    "corpus = []\n",
    "for t in merged_list:\n",
    "    corpus.append(t[2])\n",
    "\n",
    "print('TEST FOR ENHANCER {} \\n'.format(TEST_EID))\n",
    "print('Length = {} \\n'.format(len(corpus[TEST_EID].split(' '))))\n",
    "print(corpus[TEST_EID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "features = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2668x1024 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1113047 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTS FOR NODE 981 \n",
      "\n",
      "[225, 691, 231, 718, 830, 236, 73, 172, 590, 903, 315, 807, 786, 119, 779, 568, 719, 827, 967, 814, 239, 764, 927, 499, 754, 203, 50, 478, 44, 959, 187, 751, 975, 956, 1003, 250, 57, 910, 227, 56, 969, 295, 540, 916, 741, 113, 158, 299, 14, 704, 915, 484, 330, 953, 703, 943, 633, 179, 508, 639, 1009, 252, 831, 12, 259, 797, 636, 64, 452, 962, 771, 960, 1008, 944, 594, 494, 891, 159] \n",
      "\n",
      "[12, 14, 540, 44, 50, 568, 56, 57, 64, 73, 590, 594, 113, 119, 633, 636, 639, 158, 159, 172, 691, 179, 187, 703, 704, 203, 718, 719, 225, 227, 741, 231, 236, 751, 239, 754, 250, 764, 252, 259, 771, 779, 786, 797, 295, 807, 299, 814, 315, 827, 830, 831, 330, 891, 903, 910, 915, 916, 927, 943, 944, 953, 956, 959, 960, 962, 452, 967, 969, 975, 478, 484, 1003, 494, 1008, 1009, 499, 508] \n",
      "\n",
      "Number of unique words in sentence: 78 vs 78\n",
      "Comparison of sets of unique words: True \n",
      "\n",
      "  (0, 225)\t0.09889583756087965\n",
      "  (0, 691)\t0.10906175037204857\n",
      "  (0, 231)\t0.09277112814377503\n",
      "  (0, 718)\t0.11188129784919433\n",
      "  (0, 830)\t0.10418894963948112\n",
      "  (0, 236)\t0.10282575354175785\n",
      "  (0, 73)\t0.0861828934717262\n",
      "  (0, 172)\t0.09800855728077333\n",
      "  (0, 590)\t0.09263927883772234\n",
      "  (0, 903)\t0.0894098857483894\n",
      "  (0, 315)\t0.09070209452100499\n",
      "  (0, 807)\t0.09460874819399956\n",
      "  (0, 786)\t0.0881100695267997\n",
      "  (0, 119)\t0.08731448913446836\n",
      "  (0, 779)\t0.10087396666984118\n",
      "  (0, 568)\t0.28192097379150155\n",
      "  (0, 719)\t0.09670643310930542\n",
      "  (0, 827)\t0.10020587105394742\n",
      "  (0, 967)\t0.0952982597624137\n",
      "  (0, 814)\t0.10186673148660105\n",
      "  (0, 239)\t0.08859355581601921\n",
      "  (0, 764)\t0.19591944369571135\n",
      "  (0, 927)\t0.084364331217082\n",
      "  (0, 499)\t0.10342099345810811\n",
      "  (0, 754)\t0.10513758240642894\n",
      "  :\t:\n",
      "  (0, 953)\t0.08767093713379748\n",
      "  (0, 703)\t0.08622149134068006\n",
      "  (0, 943)\t0.08932765135800957\n",
      "  (0, 633)\t0.08336968301939135\n",
      "  (0, 179)\t0.10513758240642894\n",
      "  (0, 508)\t0.08916358656758067\n",
      "  (0, 639)\t0.08403058204230904\n",
      "  (0, 1009)\t0.18713919566841328\n",
      "  (0, 252)\t0.08887776016806\n",
      "  (0, 831)\t0.08015578763168828\n",
      "  (0, 12)\t0.08119269283958012\n",
      "  (0, 259)\t0.08511405678278582\n",
      "  (0, 797)\t0.1036939136566414\n",
      "  (0, 636)\t0.10325795240529898\n",
      "  (0, 64)\t0.08036145828004834\n",
      "  (0, 452)\t0.09488341469137822\n",
      "  (0, 962)\t0.09451752643382595\n",
      "  (0, 771)\t0.17914952147354837\n",
      "  (0, 960)\t0.08289773351557139\n",
      "  (0, 1008)\t0.16747154375072412\n",
      "  (0, 944)\t0.0887557607593996\n",
      "  (0, 594)\t0.07951001423386207\n",
      "  (0, 494)\t0.07781670254657287\n",
      "  (0, 891)\t0.07954379550494979\n",
      "  (0, 159)\t0.08672598961888328\n"
     ]
    }
   ],
   "source": [
    "print('TESTS FOR NODE {} \\n'.format(TEST_EID))\n",
    "\n",
    "vector = list(features[TEST_EID].indices)\n",
    "print('{} \\n'.format(vector)) # vector tokens are not ordered\n",
    "\n",
    "# Get sentence with id = test_id from df\n",
    "test_enh = getNodeById(df_ep, TEST_EID)\n",
    "sent = test_enh[2]\n",
    "\n",
    "tokens = []\n",
    "for word in sent.split(' '):\n",
    "    tokens.append(vectorizer.vocabulary_[word.lower()])\n",
    "    # used lower() because vectorizer keys are lowercased (e.g. aactg)\n",
    "\n",
    "tokens = list(set(tokens)) # since vector does not have duplicated tokens\n",
    "\n",
    "print('{} \\n'.format(tokens))\n",
    "print('Number of unique words in sentence: {} vs {}'.format(len(vector), len(tokens)))\n",
    "print('Comparison of sets of unique words: {} \\n'.format(sorted(vector) == sorted(tokens)))\n",
    "\n",
    "print(features[TEST_EID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 981 number of unique words 78 =? 78\n",
      "Node 124 number of unique words 166 =? 166\n",
      "Node 1196 number of unique words 147 =? 147\n",
      "Node 2540 number of unique words 643 =? 643\n",
      "Node 2295 number of unique words 99 =? 99\n"
     ]
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "test_eid_list = []\n",
    "\n",
    "for row in [random.randint(0, len(df_ep)) for i in range(5)]:\n",
    "    test_eid_list.append(df_ep['enhancer'][row][0])\n",
    "\n",
    "for test_eid in test_eid_list:\n",
    "    L1 = len(features[test_eid].indices)\n",
    "\n",
    "    test_enh = getNodeById(df_ep, test_eid)\n",
    "    sent = test_enh[2]\n",
    "    \n",
    "    L2 = len(set(sent.split(' ')))\n",
    "    print('Node {} number of unique words {} =? {}'.format(test_eid, L1, L2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE BINARY LABEL MATRIX (NxE)\n",
    "\n",
    "N = Number of nodes (enhancers + promoters)\n",
    "\n",
    "E = Number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=int8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.zeros(shape=(len(id_dict),2), dtype=np.int8) # 8-bit signed integer (-128 to 127)\n",
    "\n",
    "for i in range(len(df_ep)):\n",
    "    eid = df_ep['enhancer'][i][0]\n",
    "    pid = df_ep['promoter'][i][0]\n",
    "    labels[eid] = [1,0] # enhancer class\n",
    "    labels[pid] = [0,1] # promoter class\n",
    "\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST VALIDATION SPLIT\n",
    "\n",
    "**Label rate = 0.2** (the number of labeled nodes that are used for training divided by the total number of nodes in dataset)\n",
    "\n",
    "**20%** labeled training (x), **40%** unlabaled training (ux), **20%** validation (vx), **20%** test (tx)\n",
    "\n",
    "allx = x + ux + vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdPortions(id_dict):\n",
    "\n",
    "    idx = list(id_dict.values())\n",
    "    idx_allx, idx_tx = train_test_split(idx, test_size=0.2, random_state=SEED)\n",
    "    idx_x_vx, idx_ux = train_test_split(idx_allx, test_size=1-LABEL_RATE*2/0.8, random_state=SEED)\n",
    "    idx_x, idx_vx = train_test_split(idx_x_vx, test_size=0.5, random_state=SEED)\n",
    "    \n",
    "    return idx_x, idx_ux, idx_vx, idx_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 533 labeled training \n",
      " 534 validation \n",
      " 534 test \n",
      "1067 unlabeled training\n"
     ]
    }
   ],
   "source": [
    "idx_x, idx_ux, idx_vx, idx_tx = getIdPortions(id_dict)\n",
    "\n",
    "print(' {} labeled training \\n {} validation \\n {} test \\n{} unlabeled training'\n",
    "      .format(len(idx_x), len(idx_vx), len(idx_tx), len(idx_ux)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP INDEX FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_x_file = open('{}/x.index'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(idx_x, idx_x_file)\n",
    "idx_x_file.close()\n",
    "\n",
    "idx_ux_file = open('{}/ux.index'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(idx_ux, idx_ux_file)\n",
    "idx_ux_file.close()\n",
    "\n",
    "idx_vx_file = open('{}/vx.index'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(idx_vx, idx_vx_file)\n",
    "idx_vx_file.close()\n",
    "\n",
    "idx_tx_file = open('{}/tx.index'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(idx_tx, idx_tx_file)\n",
    "idx_tx_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP FEATURE VECTORS & CLASS LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = open('{}/features'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(features, features_file)\n",
    "features_file.close()\n",
    "\n",
    "labels_file = open('{}/labels'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(labels, labels_file)\n",
    "labels_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP GRAPH EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {i: np.nonzero(row)[1].tolist() for i,row in enumerate(adj)}\n",
    "\n",
    "# Print first k elements of graph\n",
    "{k: graph[k] for k in list(graph)[:15]}\n",
    "\n",
    "graph_file = open('{}/graph'.format(CELL_LINE), \"wb\")\n",
    "pkl.dump(graph, graph_file)\n",
    "graph_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD INDICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indices(cell_line):\n",
    "    idx_x_file = open('{}/x.index'.format(cell_line), \"rb\")\n",
    "    loaded_idx_x = pkl.load(idx_x_file)\n",
    "    idx_x_file.close()\n",
    "\n",
    "    idx_ux_file = open('{}/ux.index'.format(cell_line), \"rb\")\n",
    "    loaded_idx_ux = pkl.load(idx_ux_file)\n",
    "    idx_ux_file.close()\n",
    "\n",
    "    idx_vx_file = open('{}/vx.index'.format(cell_line), \"rb\")\n",
    "    loaded_idx_vx = pkl.load(idx_vx_file)\n",
    "    idx_vx_file.close()\n",
    "\n",
    "    idx_tx_file = open('{}/tx.index'.format(cell_line), \"rb\")\n",
    "    loaded_idx_tx = pkl.load(idx_tx_file)\n",
    "    idx_tx_file.close()\n",
    "    \n",
    "    return loaded_idx_x, loaded_idx_ux, loaded_idx_vx, loaded_idx_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled train indices:\t\t[2625, 2472, 1978, 1248, 1877]\tLength = 533\n",
      "Unlabeled train indices:\t[374, 206, 1348, 2556, 2088]\tLength = 1067\n",
      "Validation indices:\t\t[687, 1191, 1516, 1246, 1054]\tLength = 534\n",
      "Test indices:\t\t\t[298, 1809, 1575, 2448, 929]\tLength = 534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_idx_x, loaded_idx_ux, loaded_idx_vx, loaded_idx_tx = load_indices(CELL_LINE)\n",
    "\n",
    "print('Labeled train indices:\\t\\t{}\\tLength = {}'.format(loaded_idx_x[:5], len(loaded_idx_x)))\n",
    "print('Unlabeled train indices:\\t{}\\tLength = {}'.format(loaded_idx_ux[:5], len(loaded_idx_ux)))\n",
    "print('Validation indices:\\t\\t{}\\tLength = {}'.format(loaded_idx_vx[:5], len(loaded_idx_vx)))\n",
    "print('Test indices:\\t\\t\\t{}\\tLength = {}\\n'.format(loaded_idx_tx[:5], len(loaded_idx_tx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD FEATURE VECTORS & CLASS LABELS & GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_labels_graph(cell_line):\n",
    "\n",
    "    features_file = open('{}/features'.format(cell_line), \"rb\")\n",
    "    loaded_features = pkl.load(features_file)\n",
    "    features_file.close()\n",
    "\n",
    "    labels_file = open('{}/labels'.format(cell_line), \"rb\")\n",
    "    loaded_labels = pkl.load(labels_file)\n",
    "    labels_file.close()\n",
    "    \n",
    "    graph_file = open('{}/graph'.format(cell_line), \"rb\")\n",
    "    loaded_graph = pkl.load(graph_file)\n",
    "    graph_file.close()\n",
    "\n",
    "    loaded_adj = nx.adjacency_matrix(nx.from_dict_of_lists(loaded_graph))\n",
    "    \n",
    "    return loaded_features, loaded_labels, loaded_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_features, loaded_labels, loaded_adj = load_features_labels_graph(CELL_LINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT SUBSETS OF FEATURES & LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled train features:\t\t(533, 1024)\n",
      "Unlabeled train features:\t(1067, 1024)\n",
      "Validation features:\t\t(534, 1024)\n",
      "Test features:\t\t\t(534, 1024)\n",
      "\n",
      "Labeled train labels:\t\t(533, 2)\n",
      "Unlabeled train labels:\t\t(1067, 2)\n",
      "Validation labels:\t\t(534, 2)\n",
      "Test labels:\t\t\t(534, 2)\n"
     ]
    }
   ],
   "source": [
    "loaded_x = loaded_features[loaded_idx_x]\n",
    "loaded_y = loaded_labels[loaded_idx_x]\n",
    "\n",
    "loaded_ux = loaded_features[loaded_idx_ux]\n",
    "loaded_uy = loaded_labels[loaded_idx_ux]\n",
    "\n",
    "loaded_vx = loaded_features[loaded_idx_vx]\n",
    "loaded_vy = loaded_labels[loaded_idx_vx]\n",
    "\n",
    "loaded_tx = loaded_features[loaded_idx_tx]\n",
    "loaded_ty = loaded_labels[loaded_idx_tx]\n",
    "\n",
    "print('Labeled train features:\\t\\t{}'.format(loaded_x.shape))\n",
    "print('Unlabeled train features:\\t{}'.format(loaded_ux.shape))\n",
    "print('Validation features:\\t\\t{}'.format(loaded_vx.shape))\n",
    "print('Test features:\\t\\t\\t{}\\n'.format(loaded_tx.shape))\n",
    "\n",
    "print('Labeled train labels:\\t\\t{}'.format(loaded_y.shape))\n",
    "print('Unlabeled train labels:\\t\\t{}'.format(loaded_uy.shape))\n",
    "print('Validation labels:\\t\\t{}'.format(loaded_vy.shape))\n",
    "print('Test labels:\\t\\t\\t{}'.format(loaded_ty.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS FOR LOADED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words for node 374\n",
      "Actual dataframe -> 808\n",
      "Loaded features  -> 808\n"
     ]
    }
   ],
   "source": [
    "node_index = 0\n",
    "node_id = loaded_idx_ux[node_index]\n",
    "\n",
    "print('Number of unique words for node {}'.format(node_id))\n",
    "print('Actual dataframe -> {}'.format(len(set(getNodeById(df_ep, node_id)[2].split(' ')))))\n",
    "print('Loaded features  -> {}'.format(len(loaded_ux[node_index].indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2668x2668 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 4226 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(loaded_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2668x2668 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 4226 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(adj.A, loaded_adj.A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancer 981 -> Promoter [983]\n"
     ]
    }
   ],
   "source": [
    "print('Enhancer {} -> Promoter {}'.format(TEST_EID, adj[TEST_EID].indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancer 981 -> Promoter [983]\n"
     ]
    }
   ],
   "source": [
    "print('Enhancer {} -> Promoter {}'.format(TEST_EID, loaded_adj[TEST_EID].indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 5)\t1\n",
      "  (3, 83)\t1\n",
      "  (3, 84)\t1\n",
      "  (4, 2)\t1\n",
      "  (5, 2)\t1\n",
      "  (6, 7)\t1\n",
      "  (6, 8)\t1\n",
      "  (6, 9)\t1\n",
      "  (6, 10)\t1\n",
      "  (6, 11)\t1\n",
      "  (6, 12)\t1\n",
      "  (7, 6)\t1\n",
      "  (8, 6)\t1\n",
      "  (9, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "print(adj[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 5)\t1\n",
      "  (3, 83)\t1\n",
      "  (3, 84)\t1\n",
      "  (4, 2)\t1\n",
      "  (5, 2)\t1\n",
      "  (6, 7)\t1\n",
      "  (6, 8)\t1\n",
      "  (6, 9)\t1\n",
      "  (6, 10)\t1\n",
      "  (6, 11)\t1\n",
      "  (6, 12)\t1\n",
      "  (7, 6)\t1\n",
      "  (8, 6)\t1\n",
      "  (9, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "print(loaded_adj[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
